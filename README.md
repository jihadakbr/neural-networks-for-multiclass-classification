
# Neural Networks for Multiclass Classification

This project was completed as a part of the Honors portion of the [Advanced Learning Algorithms](https://www.coursera.org/learn/advanced-learning-algorithms) Course on [Coursera](https://www.coursera.org/).

Credit to DeepLearning.AI, Stanford, and the Coursera platform for providing the course materials and guidance.

## Objective


In this project, I will build upon the previous week's assignment to expand its capabilities in recognizing digits 0 to 9. The primary focus will be on exploring two widely used activation functions: ReLU (Rectified Linear Unit) and Softmax, specifically in the context of multiclass classification. The implementation of a neural network capable of performing multiclass classification will be carried out using Tensorflow, leveraging both ReLU and Softmax activations. By the end of this report, we will have a comprehensive understanding of how these activation functions contribute to the success of the neural network in recognizing a wide range of handwritten digits.
## Results

![Multiclass Classification](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEif48dxy8X2kbuyd0KMe1x6z06UMGWdArwEPV4F3qVeQwXQ_OgMlnt3YlRyQ3XkogTodEOmiL7pAKRp-u7jM4AWkcCRo-Vs9FI7Py84-xFLfbRgZ0QEerjO71pfJH9u1SBpaE_bx6kzYod6NC9jwPj2vcGAcSCwTkD8j9f-21UOVpg9jVohG6EF72bmbWg/s1600/multiclass-classification.png)